{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4b4085",
   "metadata": {
    "id": "cd4b4085"
   },
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559cdf17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1766871178172,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "559cdf17",
    "outputId": "4dd57932-0240-4682-b1ac-8fc4a1e60803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan  7 11:14:43 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 571.96                 Driver Version: 571.96         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8             10W /  285W |       0MiB /  16376MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA A2                    TCC   |   00000000:05:00.0 Off |                    0 |\n",
      "|  0%   32C    P8              5W /   60W |      10MiB /  15356MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a963ef19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7696,
     "status": "ok",
     "timestamp": 1766871189149,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "a963ef19",
    "outputId": "6a2384d0-6490-4978-d9e9-11574953acb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics>=8.1.0 tensorboard Augmentor opencv-python-headless tqdm PyYAML -q\n",
    "\n",
    "print(\"\\n Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b911641",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8410,
     "status": "ok",
     "timestamp": 1766871199940,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "7b911641",
    "outputId": "842b56a6-b8c7-45da-c90e-d5d25e23ffa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 4070 Ti SUPER\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87239110",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24770,
     "status": "ok",
     "timestamp": 1766871230789,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "87239110",
    "outputId": "59a6cfc5-c868-4a5f-962c-1638dbbbf50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set working directory\n",
    "WORK_DIR = \"C:\\\\Users\\\\Cerelab\\\\Desktop\\\\GroupIJS2\\\\\"\n",
    "os.makedirs(WORK_DIR, exist_ok=True)\n",
    "os.chdir(WORK_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e83e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kagglehub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebxJwjeblJT-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 222167,
     "status": "ok",
     "timestamp": 1766871460761,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "ebxJwjeblJT-",
    "outputId": "84f0093c-dc3b-4302-f93d-10215e39195e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cerelab\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/anulayakhare/crackathon-data?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.90G/9.90G [10:39<00:00, 16.6MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Cerelab\\.cache\\kagglehub\\datasets\\anulayakhare\\crackathon-data\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"anulayakhare/crackathon-data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1f23769",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1766871491751,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "e1f23769",
    "outputId": "c7f775f3-1299-475f-b0b6-6eadc3132565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing yolov9_ep/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile yolov9_ep/__init__.py\n",
    "# YOLOv9-EP Pipeline Package\n",
    "__version__ = \"1.0.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e17ebf",
   "metadata": {
    "id": "b0e17ebf"
   },
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93dd1389",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1766871499280,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "93dd1389",
    "outputId": "e57e3520-626f-4f30-bf72-190460b360e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION LOADED\n",
      "============================================================\n",
      "\n",
      "üìã Dataset: 5 Classes\n",
      "   0 ‚Üí Longitudinal_Crack\n",
      "   1 ‚Üí Transverse_Crack\n",
      "   2 ‚Üí Alligator_Crack\n",
      "   3 ‚Üí Other_Corruption\n",
      "   4 ‚Üí Pothole\n",
      "\n",
      "‚öôÔ∏è Training Settings:\n",
      "   Epochs: 80\n",
      "   Batch Size: 16\n",
      "   Image Size: 768\n",
      "   Optimizer: SGD\n",
      "\n",
      "üìä Best Model Selection: mAP50-95\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - Modify these settings for your experiment\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Dataset paths\n",
    "    \"DATASET_DIR\": \"C:\\\\Users\\\\Cerelab\\\\.cache\\\\kagglehub\\\\datasets\\\\anulayakhare\\\\crackathon-data\\\\versions\\\\1\\\\randomized_dataset\",  # Your dataset directory\n",
    "    \"OUTPUT_DIR\": \"C:\\\\Users\\\\Cerelab\\\\Desktop\\\\GroupIJS2\\\\outputs\",    # Output directory\n",
    "\n",
    "    # Dataset info\n",
    "    \"NUM_CLASSES\": 5,\n",
    "    \"CLASS_NAMES\": [\n",
    "        \"Longitudinal_Crack\",   # 0\n",
    "        \"Transverse_Crack\",     # 1\n",
    "        \"Alligator_Crack\",      # 2\n",
    "        \"Other_Corruption\",     # 3\n",
    "        \"Pothole\"               # 4\n",
    "    ],\n",
    "\n",
    "    # Training hyperparameters\n",
    "    \"EPOCHS\": 80,\n",
    "    \"BATCH_SIZE\": 16,            # Reduced for Colab GPU memory\n",
    "    \"IMG_SIZE\": 768,\n",
    "    \"OPTIMIZER\": \"SGD\",\n",
    "    \"LR0\": 0.01,                # Initial learning rate\n",
    "    \"LRF\": 0.0001,                # Final LR factor\n",
    "    \"MOMENTUM\": 0.937,\n",
    "    \"WEIGHT_DECAY\": 0.0005,\n",
    "    \"WARMUP_EPOCHS\": 3.0,\n",
    "\n",
    "    # Deterministic training\n",
    "    \"SEED\": 42,\n",
    "    \"DETERMINISTIC\": True,\n",
    "\n",
    "    # Inference thresholds\n",
    "    \"CONF_THRESHOLD\": 0.15,     # Confidence threshold\n",
    "    \"IOU_THRESHOLD\": 0.55,      # NMS IoU threshold (high for EP)\n",
    "\n",
    "    # TTA settings for EP\n",
    "    \"TTA_ENABLED\": True,\n",
    "    \"TTA_SCALES\": [0.67, 0.83, 1.0],\n",
    "    \"TTA_FLIP\": True,\n",
    "    \"TTA_SHARPEN\": True,\n",
    "    \"TTA_NOISE\": True,\n",
    "\n",
    "    # Model\n",
    "    \"PRETRAINED_WEIGHTS\": \"yolov9c.pt\",\n",
    "    \"DEVICE\": \"0\",  # GPU index\n",
    "\n",
    "    # Experiment name\n",
    "    \"EXPERIMENT_NAME\": f\"yolov9c_ep_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "\n",
    "    # Checkpoint settings\n",
    "    \"SAVE_PERIOD\": 2,          # Save checkpoint every N epochs\n",
    "    \"BEST_METRIC\": \"mAP50-95\",  # Metric for best model: \"mAP50\" or \"mAP50-95\"\n",
    "}\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(CONFIG[\"OUTPUT_DIR\"], exist_ok=True)\n",
    "os.makedirs(os.path.join(CONFIG[\"OUTPUT_DIR\"], \"runs\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(CONFIG[\"OUTPUT_DIR\"], \"tensorboard\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(CONFIG[\"OUTPUT_DIR\"], \"checkpoints\"), exist_ok=True)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION LOADED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nüìã Dataset: {CONFIG['NUM_CLASSES']} Classes\")\n",
    "for i, name in enumerate(CONFIG[\"CLASS_NAMES\"]):\n",
    "    print(f\"   {i} ‚Üí {name}\")\n",
    "print(f\"\\n‚öôÔ∏è Training Settings:\")\n",
    "print(f\"   Epochs: {CONFIG['EPOCHS']}\")\n",
    "print(f\"   Batch Size: {CONFIG['BATCH_SIZE']}\")\n",
    "print(f\"   Image Size: {CONFIG['IMG_SIZE']}\")\n",
    "print(f\"   Optimizer: {CONFIG['OPTIMIZER']}\")\n",
    "print(f\"\\nüìä Best Model Selection: {CONFIG['BEST_METRIC']}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c051f69e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1766880503930,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "c051f69e",
    "outputId": "8bc08cc9-2f1b-441d-c7e3-60a2c903d1cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Checking for checkpoints in: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\n",
      "INFO:__main__:  Found: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt\n",
      "INFO:__main__:Latest checkpoint selected: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt\n",
      "INFO:__main__:Checkpoint verified: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt (98.13 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHECKPOINT STATUS\n",
      "============================================================\n",
      "‚úÖ Found valid checkpoint: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt\n",
      "\n",
      "   To resume: Set RESUME_TRAINING = True below\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CHECKPOINT MANAGEMENT - Resume Training Support (FIXED)\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import logging\n",
    "\n",
    "# Setup logging for debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"checkpoints\")\n",
    "DRIVE_CHECKPOINT_DIR = \"/content/drive/MyDrive/yolov9_ep_checkpoints\"\n",
    "\n",
    "def find_latest_checkpoint():\n",
    "    \"\"\"Find the latest checkpoint to resume training.\"\"\"\n",
    "    checkpoints = []\n",
    "\n",
    "    # Check local runs directory - prioritize LAST checkpoint (most recent training)\n",
    "    runs_dir = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"runs\")\n",
    "    logger.info(f\"Checking for checkpoints in: {runs_dir}\")\n",
    "    \n",
    "    if os.path.exists(runs_dir):\n",
    "        for exp_dir in sorted(Path(runs_dir).iterdir(), reverse=True):\n",
    "            if exp_dir.is_dir():\n",
    "                last_pt = exp_dir / \"weights\" / \"last.pt\"\n",
    "                if last_pt.exists():\n",
    "                    mtime = last_pt.stat().st_mtime\n",
    "                    checkpoints.append((str(last_pt), mtime))\n",
    "                    logger.info(f\"  Found: {last_pt}\")\n",
    "\n",
    "    # Check Google Drive checkpoints\n",
    "    if os.path.exists(DRIVE_CHECKPOINT_DIR):\n",
    "        logger.info(f\"Checking Google Drive: {DRIVE_CHECKPOINT_DIR}\")\n",
    "        for f in sorted(Path(DRIVE_CHECKPOINT_DIR).glob(\"*.pt\"), reverse=True):\n",
    "            mtime = f.stat().st_mtime\n",
    "            checkpoints.append((str(f), mtime))\n",
    "            logger.info(f\"  Found: {f.name}\")\n",
    "\n",
    "    if checkpoints:\n",
    "        checkpoints.sort(key=lambda x: x[1], reverse=True)\n",
    "        latest = checkpoints[0][0]\n",
    "        logger.info(f\"Latest checkpoint selected: {latest}\")\n",
    "        return latest\n",
    "    \n",
    "    logger.info(\"No checkpoints found\")\n",
    "    return None\n",
    "\n",
    "def load_training_state():\n",
    "    \"\"\"Load previous training state if exists.\"\"\"\n",
    "    state_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"training_state.json\")\n",
    "    if os.path.exists(state_path):\n",
    "        try:\n",
    "            with open(state_path, 'r') as f:\n",
    "                state = json.load(f)\n",
    "                logger.info(f\"Loaded training state from: {state_path}\")\n",
    "                return state\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to load training state: {e}\")\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def verify_checkpoint(checkpoint_path):\n",
    "    \"\"\"Verify checkpoint file integrity.\"\"\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        logger.error(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "        return False\n",
    "    \n",
    "    file_size = os.path.getsize(checkpoint_path) / (1024 * 1024)\n",
    "    if file_size < 1:\n",
    "        logger.error(f\"Checkpoint file too small ({file_size:.2f} MB): {checkpoint_path}\")\n",
    "        return False\n",
    "    \n",
    "    logger.info(f\"Checkpoint verified: {checkpoint_path} ({file_size:.2f} MB)\")\n",
    "    return True\n",
    "\n",
    "# Check for existing checkpoints\n",
    "RESUME_CHECKPOINT = find_latest_checkpoint()\n",
    "PREVIOUS_STATE = load_training_state()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKPOINT STATUS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if RESUME_CHECKPOINT and verify_checkpoint(RESUME_CHECKPOINT):\n",
    "    print(f\"‚úÖ Found valid checkpoint: {RESUME_CHECKPOINT}\")\n",
    "    if PREVIOUS_STATE:\n",
    "        print(f\"   Experiment: {PREVIOUS_STATE.get('experiment_name', 'Unknown')}\")\n",
    "        print(f\"   Previous epochs: {PREVIOUS_STATE.get('epochs_completed', 'Unknown')}\")\n",
    "        metrics = PREVIOUS_STATE.get('metrics', {})\n",
    "        print(f\"   Best mAP@0.5: {metrics.get('mAP50', 0):.4f}\")\n",
    "        print(f\"   Best mAP@0.5:0.95: {metrics.get('mAP50-95', 0):.4f}\")\n",
    "    print(f\"\\n   To resume: Set RESUME_TRAINING = True below\")\n",
    "else:\n",
    "    print(\"üìù No valid checkpoint found. Training will start fresh.\")\n",
    "    RESUME_CHECKPOINT = None\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================\n",
    "# SET THIS TO RESUME TRAINING\n",
    "# ============================================================\n",
    "RESUME_TRAINING = True  # ‚Üê Change to True to resume from checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86c932",
   "metadata": {
    "id": "ef86c932"
   },
   "source": [
    "## 3. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c055a39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1766871513695,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "6c055a39",
    "outputId": "7f29653e-ff2c-4b21-d8ff-fcc4c5bc9e60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Created data.yaml at: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\data.yaml\n",
      "   Classes: 5\n",
      "   Names: ['Longitudinal_Crack', 'Transverse_Crack', 'Alligator_Crack', 'Other_Corruption', 'Pothole']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Cerelab\\\\Desktop\\\\GroupIJS2\\\\outputs\\\\data.yaml'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from glob import glob\n",
    "from collections import Counter\n",
    "\n",
    "def validate_dataset(dataset_dir):\n",
    "    \"\"\"Validate dataset structure and class distribution.\"\"\"\n",
    "    results = {\n",
    "        \"train_images\": len(glob(os.path.join(dataset_dir, \"train/images/*\"))),\n",
    "        \"train_labels\": len(glob(os.path.join(dataset_dir, \"train/labels/*.txt\"))),\n",
    "        \"val_images\": len(glob(os.path.join(dataset_dir, \"val/images/*\"))),\n",
    "        \"val_labels\": len(glob(os.path.join(dataset_dir, \"val/labels/*.txt\"))),\n",
    "        \"test_images\": len(glob(os.path.join(dataset_dir, \"test/images/*\"))),\n",
    "    }\n",
    "\n",
    "    print(\"üìä Dataset Statistics:\")\n",
    "    print(f\"  Train: {results['train_images']} images, {results['train_labels']} labels\")\n",
    "    print(f\"  Val: {results['val_images']} images, {results['val_labels']} labels\")\n",
    "    print(f\"  Test: {results['test_images']} images (no labels - for submission)\")\n",
    "\n",
    "    # Analyze class distribution in training set\n",
    "    print(\"\\nüìà Class Distribution (Training Set):\")\n",
    "    class_counts = Counter()\n",
    "    label_files = glob(os.path.join(dataset_dir, \"train/labels/*.txt\"))\n",
    "\n",
    "    for label_file in label_files:\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:\n",
    "                    class_id = int(parts[0])\n",
    "                    class_counts[class_id] += 1\n",
    "\n",
    "    total_annotations = sum(class_counts.values())\n",
    "    for class_id in range(CONFIG[\"NUM_CLASSES\"]):\n",
    "        count = class_counts.get(class_id, 0)\n",
    "        pct = (count / total_annotations * 100) if total_annotations > 0 else 0\n",
    "        bar = \"‚ñà\" * int(pct / 2)\n",
    "        print(f\"   {class_id} ({CONFIG['CLASS_NAMES'][class_id]:<20}): {count:>5} ({pct:>5.1f}%) {bar}\")\n",
    "\n",
    "    print(f\"\\n   Total annotations: {total_annotations}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def create_data_yaml(dataset_dir, output_path, nc, names):\n",
    "    \"\"\"Create data.yaml for YOLO training.\"\"\"\n",
    "    data_config = {\n",
    "        'path': os.path.abspath(dataset_dir),\n",
    "        'train': 'train/images',\n",
    "        'val': 'val/images',\n",
    "        'test': 'test/images',\n",
    "        'nc': nc,\n",
    "        'names': names\n",
    "    }\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        yaml.dump(data_config, f, default_flow_style=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Created data.yaml at: {output_path}\")\n",
    "    print(f\"   Classes: {nc}\")\n",
    "    print(f\"   Names: {names}\")\n",
    "    return output_path\n",
    "\n",
    "# Validate dataset\n",
    "\n",
    "# Create data.yaml\n",
    "DATA_YAML = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"data.yaml\")\n",
    "create_data_yaml(\n",
    "    CONFIG[\"DATASET_DIR\"],\n",
    "    DATA_YAML,\n",
    "    CONFIG[\"NUM_CLASSES\"],\n",
    "    CONFIG[\"CLASS_NAMES\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa60af20",
   "metadata": {
    "id": "fa60af20"
   },
   "source": [
    "## 4. Training YOLOv9-Compact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfdfbd3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1766871544416,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "dfdfbd3b",
    "outputId": "82512275-aa96-465a-a7d5-82967182d5e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print(f\"üé≤ Random seed set to {seed}\")\n",
    "\n",
    "# Set seed for deterministic training\n",
    "if CONFIG[\"DETERMINISTIC\"]:\n",
    "    set_seed(CONFIG[\"SEED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86d3c662",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6882,
     "status": "ok",
     "timestamp": 1766871553337,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "86d3c662",
    "outputId": "a91371ef-363a-4c70-b211-40ca3e50ab8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained weights: yolov9c.pt\n",
      "\n",
      "‚úÖ Model loaded successfully!\n",
      "Model type: YOLOv9-Compact\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained YOLOv9-Compact\n",
    "print(f\"Loading pretrained weights: {CONFIG['PRETRAINED_WEIGHTS']}\")\n",
    "model = YOLO(CONFIG[\"PRETRAINED_WEIGHTS\"])\n",
    "\n",
    "print(f\"\\n‚úÖ Model loaded successfully!\")\n",
    "print(f\"Model type: YOLOv9-Compact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9929b126",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766871563131,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "9929b126",
    "outputId": "223361e7-8a5e-4e4a-ffdc-51509d458e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Configuration:\n",
      "----------------------------------------\n",
      "  data: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\data.yaml\n",
      "  epochs: 80\n",
      "  batch: 16\n",
      "  imgsz: 768\n",
      "  optimizer: SGD\n",
      "  lr0: 0.01\n",
      "  lrf: 0.0001\n",
      "  momentum: 0.937\n",
      "  weight_decay: 0.0005\n",
      "  warmup_epochs: 3.0\n",
      "  cos_lr: True\n",
      "  amp: True\n",
      "  seed: 42\n",
      "  deterministic: True\n",
      "  project: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\n",
      "  name: yolov9c_ep_20260107_151027\n",
      "  exist_ok: True\n",
      "  patience: 30\n",
      "  device: 0\n",
      "  workers: 6\n",
      "  save: True\n",
      "  save_period: 2\n",
      "  degrees: 0.0\n",
      "  shear: 0.0\n",
      "  flipud: 0.0\n",
      "  fliplr: 0.5\n",
      "  mosaic: 1.0\n",
      "  mixup: 0.0\n",
      "  close_mosaic: 10\n",
      "  val: True\n",
      "  plots: True\n",
      "----------------------------------------\n",
      "üìä Best model will be saved based on: mAP@0.5:0.95\n",
      "üíæ Checkpoints saved every 2 epochs\n"
     ]
    }
   ],
   "source": [
    "# Training configuration - mAP-based best model selection\n",
    "TRAIN_ARGS = {\n",
    "    'data': DATA_YAML,\n",
    "    'epochs': CONFIG[\"EPOCHS\"],\n",
    "    'batch': CONFIG[\"BATCH_SIZE\"],\n",
    "    'imgsz': CONFIG[\"IMG_SIZE\"],\n",
    "\n",
    "    # Optimizer settings (SGD)\n",
    "    'optimizer': CONFIG[\"OPTIMIZER\"],\n",
    "    'lr0': CONFIG[\"LR0\"],\n",
    "    'lrf': CONFIG[\"LRF\"],\n",
    "    'momentum': CONFIG[\"MOMENTUM\"],\n",
    "    'weight_decay': CONFIG[\"WEIGHT_DECAY\"],\n",
    "    'warmup_epochs': CONFIG[\"WARMUP_EPOCHS\"],        \n",
    "    'cos_lr': True,         # Better LR decay than linear\n",
    "    'amp': True, \n",
    "\n",
    "    # Deterministic training\n",
    "    'seed': CONFIG[\"SEED\"],\n",
    "    'deterministic': CONFIG[\"DETERMINISTIC\"],\n",
    "\n",
    "    # Output settings\n",
    "    'project': os.path.join(CONFIG[\"OUTPUT_DIR\"], \"runs\"),\n",
    "    'name': CONFIG[\"EXPERIMENT_NAME\"],\n",
    "    'exist_ok': True,\n",
    "\n",
    "    # Training settings\n",
    "    'patience': 30,\n",
    "    'device': CONFIG[\"DEVICE\"],\n",
    "    'workers': 6,\n",
    "\n",
    "    # Checkpoint settings - saves best based on mAP (default behavior)\n",
    "    'save': True,\n",
    "    'save_period': CONFIG[\"SAVE_PERIOD\"],  # Save every N epochs\n",
    "\n",
    "    # Augmentation (NO rotation to preserve orientation)\n",
    "    'degrees': 0.0,\n",
    "    'shear': 0.0,\n",
    "    'flipud': 0.0,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.0,\n",
    "    'close_mosaic': 10,\n",
    "\n",
    "    # Validation\n",
    "    'val': True,\n",
    "    'plots': True,\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(\"-\"*40)\n",
    "for key, value in TRAIN_ARGS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"-\"*40)\n",
    "print(f\"üìä Best model will be saved based on: mAP@0.5:0.95\")\n",
    "print(f\"üíæ Checkpoints saved every {CONFIG['SAVE_PERIOD']} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7c0c78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8d7c0c78",
    "outputId": "d8b7f0d1-3b07-4a66-fcf1-b732550fa7ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Training arguments: {'data': 'C:\\\\Users\\\\Cerelab\\\\Desktop\\\\GroupIJS2\\\\outputs\\\\data.yaml', 'epochs': 80, 'batch': 16, 'imgsz': 768, 'optimizer': 'SGD', 'lr0': 0.01, 'lrf': 0.0001, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'cos_lr': True, 'amp': True, 'seed': 42, 'deterministic': True, 'project': 'C:\\\\Users\\\\Cerelab\\\\Desktop\\\\GroupIJS2\\\\outputs\\\\runs', 'name': 'yolov9c_ep_20260107_111459', 'exist_ok': True, 'patience': 30, 'device': '0', 'workers': 6, 'save': True, 'save_period': 2, 'degrees': 0.0, 'shear': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'close_mosaic': 10, 'val': True, 'plots': True, 'resume': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üöÄ STARTING TRAINING\n",
      "============================================================\n",
      "\n",
      "üìÇ RESUMING from checkpoint: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt\n",
      "   Verifying checkpoint integrity...\n",
      "   ‚úÖ Checkpoint loaded successfully\n",
      "\n",
      "============================================================\n",
      "New https://pypi.org/project/ultralytics/8.3.248 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.243  Python-3.12.1 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=80, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=768, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.0001, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov9c_ep_20260103_112944, nbs=64, nms=False, opset=None, optimize=False, optimizer=SGD, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs, rect=False, resume=C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944, save_frames=False, save_json=False, save_period=2, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=6, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n",
      "  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      "  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n",
      "  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      "  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n",
      " 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n",
      " 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n",
      " 22        [15, 18, 21]  1   5586655  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      "YOLOv9c summary: 358 layers, 25,533,087 parameters, 25,533,071 gradients, 103.7 GFLOPs\n",
      "\n",
      "Transferred 937/937 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 404.0345.8 MB/s, size: 772.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Cerelab\\.cache\\kagglehub\\datasets\\anulayakhare\\crackathon-data\\versions\\1\\randomized_dataset\\train\\labels.cache... 26385 images, 8073 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 26385/26385  0.0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Cerelab\\.cache\\kagglehub\\datasets\\anulayakhare\\crackathon-data\\versions\\1\\randomized_dataset\\train\\images\\000641.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Cerelab\\.cache\\kagglehub\\datasets\\anulayakhare\\crackathon-data\\versions\\1\\randomized_dataset\\train\\images\\005751.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mC:\\Users\\Cerelab\\.cache\\kagglehub\\datasets\\anulayakhare\\crackathon-data\\versions\\1\\randomized_dataset\\train\\images\\030717.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 187.6138.1 MB/s, size: 409.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Cerelab\\.cache\\kagglehub\\datasets\\anulayakhare\\crackathon-data\\versions\\1\\randomized_dataset\\val\\labels.cache... 6000 images, 1792 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6000/6000 6.0Mit/s 0.0s\n",
      "Plotting labels to C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.937) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias(decay=0.0)\n",
      "Resuming training C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt from epoch 76 to 80 total epochs\n",
      "Closing dataloader mosaic\n",
      "Image sizes 768 train, 768 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\u001b[0m\n",
      "Starting training for 80 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      76/80      14.1G      1.231      1.043      1.343          2        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1650/1650 2.9it/s 9:28<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 4.1it/s 46.0s0.3ss\n",
      "                   all       6000      10443      0.664      0.605      0.649      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      77/80      14.2G      1.231      1.033      1.342          1        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1650/1650 2.9it/s 9:26<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 4.1it/s 46.1s0.3ss\n",
      "                   all       6000      10443      0.663      0.606      0.649      0.354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      78/80      14.1G      1.225      1.023      1.337          1        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1650/1650 2.9it/s 9:26<0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 4.1it/s 45.8s0.3ss\n",
      "                   all       6000      10443       0.66      0.607      0.649      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      79/80      14.2G      1.228      1.024      1.334          0        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1650/1650 2.8it/s 9:51<0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 3.4it/s 55.0s0.3ss\n",
      "                   all       6000      10443      0.661      0.607      0.649      0.353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      80/80      14.2G      1.221      1.021      1.334          6        768: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1650/1650 2.7it/s 10:06<0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 3.6it/s 51.6s0.3ss\n",
      "                   all       6000      10443       0.66      0.608      0.649      0.353\n",
      "\n",
      "5 epochs completed in 0.874 hours.\n",
      "Optimizer stripped from C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt, 51.6MB\n",
      "Optimizer stripped from C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\best.pt, 51.6MB\n",
      "\n",
      "Validating C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\best.pt...\n",
      "Ultralytics 8.3.243  Python-3.12.1 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4070 Ti SUPER, 16376MiB)\n",
      "YOLOv9c summary (fused): 156 layers, 25,323,103 parameters, 0 gradients, 102.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 188/188 3.5it/s 53.9s0.3ss\n",
      "                   all       6000      10443      0.662      0.605      0.649      0.354\n",
      "    Longitudinal_Crack       2171       4093      0.665      0.576      0.621      0.352\n",
      "      Transverse_Crack       1209       1830      0.645      0.591      0.634      0.314\n",
      "       Alligator_Crack       1353       1698      0.668      0.625      0.693      0.388\n",
      "      Other_Corruption       1170       1737      0.689      0.747       0.76      0.483\n",
      "               Pothole        577       1085      0.646      0.487      0.538      0.231\n",
      "Speed: 0.1ms preprocess, 5.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\u001b[0m\n",
      "\n",
      "============================================================\n",
      "‚úÖ TRAINING COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# START TRAINING (FIXED - with proper resume)\n",
    "# ==========================================\n",
    "import shutil\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Determine resume mode\n",
    "should_resume = RESUME_TRAINING and RESUME_CHECKPOINT\n",
    "\n",
    "if should_resume:\n",
    "    print(f\"üìÇ RESUMING from checkpoint: {RESUME_CHECKPOINT}\")\n",
    "    print(f\"   Verifying checkpoint integrity...\")\n",
    "    \n",
    "    try:\n",
    "        model = YOLO(RESUME_CHECKPOINT)\n",
    "        TRAIN_ARGS['resume'] = True\n",
    "        # Remove conflicting args when resuming\n",
    "        if 'exist_ok' in TRAIN_ARGS:\n",
    "            TRAIN_ARGS['exist_ok'] = True  # Allow resume to overwrite\n",
    "        print(f\"   ‚úÖ Checkpoint loaded successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed to load checkpoint: {e}\")\n",
    "        print(f\"   Starting fresh instead...\")\n",
    "        model = YOLO(CONFIG[\"PRETRAINED_WEIGHTS\"])\n",
    "        TRAIN_ARGS['resume'] = True\n",
    "else:\n",
    "    print(\"üÜï Starting FRESH training\")\n",
    "    print(f\"   Loading pretrained weights: {CONFIG['PRETRAINED_WEIGHTS']}\")\n",
    "    try:\n",
    "        model = YOLO(CONFIG[\"PRETRAINED_WEIGHTS\"])\n",
    "        TRAIN_ARGS['resume'] = False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load pretrained model: {e}\")\n",
    "        raise\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "\n",
    "# Train with error handling for checkpoint recovery\n",
    "training_completed = False\n",
    "try:\n",
    "    logger.info(f\"Training arguments: {TRAIN_ARGS}\")\n",
    "    results = model.train(**TRAIN_ARGS)\n",
    "    training_completed = True\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ TRAINING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    training_completed = False\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚ö†Ô∏è TRAINING INTERRUPTED BY USER\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"‚úÖ Checkpoint saved automatically. To resume:\")\n",
    "    print(\"  1. Set RESUME_TRAINING = True in checkpoint cell\")\n",
    "    print(\"  2. Re-run from checkpoint cell onwards\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"CUDA\" in str(e) or \"out of memory\" in str(e):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"‚ùå GPU/Memory Error\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Solutions:\")\n",
    "        print(\"  ‚Ä¢ Reduce BATCH_SIZE in CONFIG\")\n",
    "        print(\"  ‚Ä¢ Reduce IMG_SIZE\")\n",
    "        print(\"  ‚Ä¢ Clear GPU cache: torch.cuda.empty_cache()\")\n",
    "        print(\"  ‚Ä¢ Set RESUME_TRAINING=True to continue later\")\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    training_completed = False\n",
    "    print(f\"\\n‚ùå Training error: {e}\")\n",
    "    print(\"Check checkpoint was saved for resume.\")\n",
    "    logger.exception(\"Training failed with exception:\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e3562cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1766880461822,
     "user": {
      "displayName": "Tanmay Bhatkar",
      "userId": "04369575101502797567"
     },
     "user_tz": -330
    },
    "id": "0e3562cd",
    "outputId": "9292305c-ad2c-40e6-d9af-bab49fda7288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä FINAL TRAINING METRICS\n",
      "============================================================\n",
      "  Precision:      0.6625\n",
      "  Recall:         0.6052\n",
      "  F1-Score:       0.6326\n",
      "  mAP@0.5:        0.6489  ‚Üê Primary metric\n",
      "  mAP@0.5:0.95:   0.3537  ‚Üê Best model selection\n",
      "============================================================\n",
      "\n",
      "üìÅ Model Locations:\n",
      "  Best (mAP): C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\best.pt\n",
      "  Last:       C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\runs\\yolov9c_ep_20260103_112944\\weights\\last.pt\n",
      "\n",
      "üíæ mAP checkpoint saved: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\checkpoints\\yolov9c_mAP50_0.6489_mAP50-95_0.3537_20260107_121404.pt\n",
      "\n",
      "üìã Training state saved: C:\\Users\\Cerelab\\Desktop\\GroupIJS2\\outputs\\training_state.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TRAINING RESULTS & CHECKPOINT SAVING (mAP-based)\n",
    "# ============================================================\n",
    "\n",
    "if 'results' in dir() and results is not None:\n",
    "    # Extract metrics\n",
    "    precision = results.results_dict.get('metrics/precision(B)', 0)\n",
    "    recall = results.results_dict.get('metrics/recall(B)', 0)\n",
    "    mAP50 = results.results_dict.get('metrics/mAP50(B)', 0)\n",
    "    mAP50_95 = results.results_dict.get('metrics/mAP50-95(B)', 0)\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìä FINAL TRAINING METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Precision:      {precision:.4f}\")\n",
    "    print(f\"  Recall:         {recall:.4f}\")\n",
    "    print(f\"  F1-Score:       {f1:.4f}\")\n",
    "    print(f\"  mAP@0.5:        {mAP50:.4f}  ‚Üê Primary metric\")\n",
    "    print(f\"  mAP@0.5:0.95:   {mAP50_95:.4f}  ‚Üê Best model selection\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Get model paths\n",
    "    BEST_MODEL = os.path.join(results.save_dir, \"weights\", \"best.pt\")\n",
    "    LAST_MODEL = os.path.join(results.save_dir, \"weights\", \"last.pt\")\n",
    "\n",
    "    print(f\"\\nüìÅ Model Locations:\")\n",
    "    print(f\"  Best (mAP): {BEST_MODEL}\")\n",
    "    print(f\"  Last:       {LAST_MODEL}\")\n",
    "\n",
    "    # Save mAP-based checkpoint with metrics in filename\n",
    "    def save_map_checkpoint(model_path, mAP50, mAP50_95, checkpoint_dir):\n",
    "        \"\"\"Save checkpoint with mAP scores in filename.\"\"\"\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"‚ö†Ô∏è Model not found: {model_path}\")\n",
    "            return None\n",
    "\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        checkpoint_name = f\"yolov9c_mAP50_{mAP50:.4f}_mAP50-95_{mAP50_95:.4f}_{timestamp}.pt\"\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "\n",
    "        shutil.copy(model_path, checkpoint_path)\n",
    "        print(f\"\\nüíæ mAP checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "        # Backup to Google Drive\n",
    "        if os.path.exists(\"/content/drive/MyDrive\"):\n",
    "            os.makedirs(DRIVE_CHECKPOINT_DIR, exist_ok=True)\n",
    "            drive_path = os.path.join(DRIVE_CHECKPOINT_DIR, checkpoint_name)\n",
    "            shutil.copy(model_path, drive_path)\n",
    "            print(f\"‚òÅÔ∏è Backed up to Drive: {drive_path}\")\n",
    "\n",
    "        return checkpoint_path\n",
    "\n",
    "    # Save best model checkpoint\n",
    "    MAP_CHECKPOINT = save_map_checkpoint(BEST_MODEL, mAP50, mAP50_95, CHECKPOINT_DIR)\n",
    "\n",
    "    # Save training state for resume\n",
    "    training_state = {\n",
    "        'experiment_name': CONFIG[\"EXPERIMENT_NAME\"],\n",
    "        'epochs_completed': CONFIG[\"EPOCHS\"],\n",
    "        'best_model': BEST_MODEL,\n",
    "        'last_model': LAST_MODEL,\n",
    "        'map_checkpoint': MAP_CHECKPOINT,\n",
    "        'metrics': {\n",
    "            'precision': float(precision),\n",
    "            'recall': float(recall),\n",
    "            'f1': float(f1),\n",
    "            'mAP50': float(mAP50),\n",
    "            'mAP50-95': float(mAP50_95)\n",
    "        },\n",
    "        'config': {k: str(v) if not isinstance(v, (int, float, bool, list)) else v\n",
    "                   for k, v in CONFIG.items()},\n",
    "        'timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "    state_path = os.path.join(CONFIG[\"OUTPUT_DIR\"], \"training_state.json\")\n",
    "    with open(state_path, 'w') as f:\n",
    "        json.dump(training_state, f, indent=2)\n",
    "    print(f\"\\nüìã Training state saved: {state_path}\")\n",
    "\n",
    "    # Also save to Drive\n",
    "    if os.path.exists(\"/content/drive/MyDrive\"):\n",
    "        drive_state_path = os.path.join(DRIVE_CHECKPOINT_DIR, \"training_state.json\")\n",
    "        with open(drive_state_path, 'w') as f:\n",
    "            json.dump(training_state, f, indent=2)\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training results available. Check if training completed.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
