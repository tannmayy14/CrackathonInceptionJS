# Road Defect Detection using YOLOv9

> **Team InceptionJS** | Crackathon Hackathon Submission

## ğŸ¯ Project Overview

This project implements an advanced **road defect detection system** using YOLOv9 (You Only Look Once version 9) deep learning architecture. The model is trained to detect and classify various types of road damage from images, enabling automated infrastructure assessment and maintenance prioritization.

## ğŸ“‹ Problem Statement

Road infrastructure maintenance is critical for public safety and transportation efficiency. Manual inspection of road surfaces is:
- Time-consuming and labor-intensive
- Prone to human error and inconsistency
- Difficult to scale across large road networks

This solution automates the detection process using computer vision and deep learning.

## ğŸ·ï¸ Detection Classes

The model identifies **5 types of road defects**:

| Class ID | Defect Type | Description |
|----------|-------------|-------------|
| 0 | **Longitudinal Crack** | Cracks running parallel to the road direction |
| 1 | **Transverse Crack** | Cracks running perpendicular to the road direction |
| 2 | **Alligator Crack** | Interconnected cracks resembling alligator skin |
| 3 | **Other Corruption** | Miscellaneous road surface damage |
| 4 | **Pothole** | Bowl-shaped depressions in the road surface |

## ğŸ› ï¸ Technical Architecture

### Model Configuration

- **Base Model**: YOLOv9c (YOLOv9 Compact)
- **Pre-trained Weights**: `yolov9c.pt`
- **Image Size**: 768Ã—768 pixels
- **Framework**: Ultralytics YOLO

### Training Hyperparameters

| Parameter | Value |
|-----------|-------|
| Epochs | 80 |
| Batch Size | 16 |
| Image Size | 768 |
| Optimizer | SGD |
| Initial Learning Rate | 0.01 |
| Final Learning Rate | 0.0001 |
| Momentum | 0.937 |
| Weight Decay | 0.0005 |
| Warmup Epochs | 3.0 |

### Inference Settings

| Parameter | Value |
|-----------|-------|
| Confidence Threshold | 0.15 |
| IoU Threshold | 0.55 |
| Test Time Augmentation (TTA) | Enabled |

### TTA (Test Time Augmentation) Configuration

- **Scales**: [0.67, 0.83, 1.0]
- **Flip Augmentation**: Enabled
- **Sharpen**: Enabled
- **Noise Augmentation**: Enabled

## ğŸ“ Project Structure

```
InceptionJS_Submissions/
â”œâ”€â”€ README.md                 # Project documentation
â”œâ”€â”€ best.pt                   # Trained model weights
â”œâ”€â”€ trainingModel.ipynb       # Training pipeline notebook
â”œâ”€â”€ Inference.ipynb           # Inference/prediction notebook
â”œâ”€â”€ InceptionJSReport.pdf     # Detailed project report
â””â”€â”€ predictions/              # Model predictions (YOLO format)
    â”œâ”€â”€ 000004.txt
    â”œâ”€â”€ 000019.txt
    â””â”€â”€ ... (prediction files for test images)
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended)
- Jupyter Notebook/Lab

### Installation

```bash
# Install required packages
pip install ultralytics>=8.1.0 tensorboard opencv-python-headless tqdm PyYAML kagglehub
```

### Dataset

The project uses the Crackathon dataset from Kaggle:

```python
import kagglehub

# Download dataset
path = kagglehub.dataset_download("anulayakhare/crackathon-data")
print("Path to dataset files:", path)
```

### Running Inference

1. Open `Inference.ipynb` in Jupyter
2. Run all cells sequentially
3. Predictions will be saved to the `predictions/` folder

```python
from ultralytics import YOLO

# Load trained model
model = YOLO("best.pt")

# Run inference
results = model.predict(
    source="path/to/test/images",
    save_txt=True,
    save_conf=True,
    conf=0.1,
    iou=0.55
)
```

### Training (Optional)

To retrain the model:

1. Open `trainingModel.ipynb`
2. Modify configuration settings as needed
3. Run the training pipeline

## ğŸ“Š Prediction Format

Predictions are saved in YOLO format (`.txt` files):

```
<class_id> <x_center> <y_center> <width> <height> <confidence>
```

- All coordinates are normalized (0-1)
- One file per image with the same base name
- Empty files indicate no detections

## ğŸ’¡ Key Features

- âœ… **Multi-class Detection**: Identifies 5 different road defect types
- âœ… **High Accuracy**: Trained with optimized hyperparameters
- âœ… **TTA Support**: Test-time augmentation for improved predictions
- âœ… **Checkpoint Resume**: Training can be resumed from checkpoints
- âœ… **GPU Acceleration**: Optimized for CUDA-enabled GPUs

## ğŸ“ˆ Evaluation Metrics

The model is evaluated using:
- **mAP50**: Mean Average Precision at IoU threshold 0.50
- **mAP50-95**: Mean Average Precision averaged over IoU thresholds from 0.50 to 0.95

## ğŸ”§ Reproducibility

For deterministic training:

```python
CONFIG = {
    "SEED": 42,
    "DETERMINISTIC": True,
    ...
}
```

## ğŸ“š Files Description

| File | Description |
|------|-------------|
| `best.pt` | Trained model weights (best performance) |
| `trainingModel.ipynb` | Complete training pipeline with data preprocessing |
| `Inference.ipynb` | Inference notebook for running predictions |
| `predictions/` | Output directory containing YOLO format predictions |

## ğŸ¤ Team InceptionJS

This project was developed as part of the **Crackathon** hackathon competition.

## ğŸ“„ License

This project is submitted as part of a hackathon competition. Please refer to the competition guidelines for usage terms.

---

**Note**: Ensure GPU availability for optimal performance. Training and inference can be performed on CPU but will be significantly slower.
